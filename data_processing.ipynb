{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import math\n",
    "from datetime import datetime\n",
    "import os\n",
    "from tqdm import trange, tqdm\n",
    "import re\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "import csv\n",
    "import unicodedata\n",
    "import html\n",
    "from io import StringIO\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import numpy as np\n",
    "from numpy import ndarray \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from nptyping import NDArray, Int, Shape\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "import nltk\n",
    "import ssl\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "\n",
    "from piazza_api import Piazza\n",
    "from piazza_api.network import Network\n",
    "\n",
    "CRED_FILE = \"creds.json\"\n",
    "\n",
    "\n",
    "\"\"\"Custom Types\"\"\"\n",
    "Answer = Dict[str,Dict[str,Union[str,int]]]\n",
    "Post = Dict[str,Union[str, Union[str,int,List]]]\n",
    "\n",
    "\"\"\"Macros\"\"\"\n",
    "# who the answer is coming from\n",
    "STUDENT, INSTRUCTOR, STUDENT_ENDORSED_ANSWERER = 0, 1, 2\n",
    "EPSILON = 1e-05\n",
    "\n",
    "# folder categories\n",
    "GENERAL, LECTURES, ASSIGNMENTS, TESTS = 0, 1, 2, 3\n",
    "\n",
    "# labels for sentiment\n",
    "LABEL_0, LABEL_1, LABEL_2 = 0, 1, 2\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHTMLParser(HTMLParser):\n",
    "    \"\"\"taken from: [1]\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    \"\"\"strips html tags and substitutes html entities \"\"\"\n",
    "    #html = html.unescape(html)\n",
    "    s =  MyHTMLParser()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login() -> Tuple[dict, Network]:\n",
    "    \"\"\"logs user into Piazza\"\"\"\n",
    "\n",
    "    email:str \n",
    "    password:str \n",
    "    courseid:str \n",
    "\n",
    "    with open(CRED_FILE) as f:\n",
    "        creds = json.load(f)\n",
    "        email, password, courseid = creds['email'], creds['password'], creds['courseid']\n",
    "\n",
    "\n",
    "    #print(f\"email: {email} \\npassword: {password} \\ncourseid: {courseid}\")\n",
    "\n",
    "\n",
    "    p: Piazza = Piazza()\n",
    "    p.user_login(email, password)\n",
    "    user_profile: dict = p.get_user_profile()\n",
    "    course: Network = p.network(courseid)\n",
    "    return user_profile, course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_creator(post: Post):\n",
    "    for entry in post['change_log']:\n",
    "        if entry['type'] == 'create':\n",
    "            return entry['uid']\n",
    "\n",
    "\n",
    "def get_post_created(post: Post):\n",
    "    \"\"\"get time post was created\"\"\"\n",
    "    for entry in post['change_log']:\n",
    "        if entry['type'] == 'create':\n",
    "            return entry['when']\n",
    "\n",
    "\n",
    "def get_posts_by_student(filename:str, student_id:str) -> List[Post]:\n",
    "    student_posts = []\n",
    "    with open(filename, 'r') as f:\n",
    "        all_posts = json.load(f)\n",
    "        for p in all_posts:\n",
    "            if get_post_creator(p) == student_id:\n",
    "                student_posts.append(p)\n",
    "    return student_posts\n",
    "\n",
    "\n",
    "def get_endorsed_students(course: Network) -> Tuple[Dict, Dict]:\n",
    "    endorsed_users = {}\n",
    "    non_endorsed_users = {}\n",
    "    users = course.get_all_users()\n",
    "    for u in users:\n",
    "        if u['endorser']:\n",
    "            endorsed_users[u['id']] = u['name']\n",
    "        else:\n",
    "            non_endorsed_users[u['id']] = u['name']\n",
    "\n",
    "\n",
    "    return endorsed_users, non_endorsed_users\n",
    "\n",
    "\n",
    "def is_private(post: Post) -> bool:\n",
    "    \"\"\" Return true if post is private \"\"\"\n",
    "    for entry in post['change_log']:\n",
    "        if entry['type'] == 'create':\n",
    "            return True if entry['v'] == 'private' else False\n",
    "\n",
    "\n",
    "\n",
    "def get_answers(post:Post, endorsed_students: Dict) -> List[Dict[str, Answer]]:\n",
    "    \"\"\" Get student and instructor answers \"\"\"\n",
    "\n",
    "    answers = {}\n",
    "    answers['s_answer'] = {}\n",
    "    answers['i_answer'] = {}\n",
    "\n",
    "    for t in answers.keys():\n",
    "        for ans in post['children']:\n",
    "            if ans['type'] == t:      \n",
    "                vals = answers[t]\n",
    "                text = ans['history'][0]['content']\n",
    "                #text = strip_tags(text)\n",
    "                vals['text'] = text\n",
    "                vals['poster'] = ans['history'][0]['uid']\n",
    "                vals['date'] = ans['history'][0]['created']\n",
    "                vals['num_helpful'] = len(ans['tag_endorse_arr'])\n",
    "                # post creator is same student that liked response\n",
    "                if get_post_creator(post) in ans['tag_endorse_arr']:\n",
    "                    vals['is_helpful'] = True \n",
    "                else:\n",
    "                    vals['is_helpful'] = False\n",
    "\n",
    "                if ans['type'] == \"s_answer\":\n",
    "                    \n",
    "                    student_poster_id = ans['history'][0]['uid'] # id of the most recent student answer editor\n",
    "                     # check if student is endorsed (actually not a valid way of checking)\n",
    "                    vals['is_endorser'] = False\n",
    "                    if student_poster_id in endorsed_students:\n",
    "                        vals['is_endorser'] = True\n",
    "                   \n",
    "                break\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Convert raw Piazza data to csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_posts_json(filename:str, course:Network) -> None:\n",
    "    \"\"\"Create json of all posts saved in current directory\"\"\"\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"{filename} already exists!\")\n",
    "        return \n",
    "    posts = course.iter_all_posts()\n",
    "    all_posts = []\n",
    "    #text = json.dumps(post['children'][1], sort_keys=True, indent=4)\n",
    "    try:\n",
    "        for p in tqdm(posts):\n",
    "            all_posts.append(p)\n",
    "    \n",
    "    finally:\n",
    "        print('------------------------------------')\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(all_posts, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def json_to_csv(json_file_path: str, csv_filename: str, course: Network, is_overwrite_csv: bool=False) -> None:\n",
    "    \"\"\" \n",
    "    :param json_file_path: Path to json file to convert to csv\n",
    "    :param csv_filename: Name of csv file to save to cur directory\n",
    "    :param course: Used to extract student profile to determine whether they are endorsed. **Actually not a valid way of checking**\n",
    "    \"\"\"\n",
    "\n",
    "    schema = (\"post_id,is_private,question_title,question,folders,student_poster_name,date_question_posted,\" \n",
    "    \"student_answer,student_answer_name,date_student_answer_posted,is_student_endorsed,is_student_helpful,\"\n",
    "    \"instructor_answer,instructor_answer_name,date_instructor_answer_posted,is_instructor_helpful,\" \n",
    "    \"is_followup\\n\")\n",
    "\n",
    "    parser = MyHTMLParser()\n",
    "\n",
    "    endorsed_students = get_endorsed_students(course)[0]\n",
    "\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        with open(csv_filename, 'w') as csv_file:\n",
    "            csv_file.write(schema)\n",
    "            posts = json.load(json_file)\n",
    "            for post in tqdm(posts):   \n",
    "                row = [] \n",
    "                if post['type'] == 'question':\n",
    "                    question = post['history'][0] # newest update of question. Change index to -1 for oldest\n",
    "                    question_title = question['subject']\n",
    "                    question_content = question['content']\n",
    "                    folders = ','.join(post['folders'])\n",
    "                    date_created = get_post_created(post)\n",
    "                    answers = get_answers(post, endorsed_students)\n",
    "                    student_answer = answers['s_answer']\n",
    "                    instructor_answer = answers['i_answer']\n",
    "                 \n",
    "\n",
    "                    row = [post['nr'], is_private(post), question_title, question_content, folders, get_post_creator(post), date_created]\n",
    "                    s_row, i_row = [], []\n",
    "                    if student_answer:\n",
    "                        s_row = [student_answer['text'], student_answer['poster'], student_answer['date'], str(student_answer['is_endorser']), str(student_answer['is_helpful'])] \n",
    "                    else:\n",
    "                        s_row = [None, None, None, None, None]\n",
    "\n",
    "                    if instructor_answer:\n",
    "                        i_row = [instructor_answer['text'], instructor_answer['poster'], instructor_answer['date'], str(instructor_answer['is_helpful'])] \n",
    "                    else:\n",
    "                        i_row = [None, None, None, None]\n",
    "                    \n",
    "                    row = row + s_row + i_row\n",
    "\n",
    "                    is_followup = 'False'\n",
    "\n",
    "                    for c in post['children']:\n",
    "                        if c['type'] == 'followup':\n",
    "                            is_followup = 'True'\n",
    "                    \n",
    "                    row += [is_followup]\n",
    "\n",
    "                    post_writer = csv.writer(csv_file)\n",
    "                    post_writer.writerow(row)\n",
    "                    \n",
    "                    csv_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_profile,course = login()\n",
    "\n",
    "#export_posts_json(\"csc108_fall2021.json\", course)\n",
    "#json_to_csv(\"./csc108_fall2021.json\", \"csc108_fall2021.csv\", course)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually viewing users and posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_profile,course = login()\n",
    "\n",
    "# user = course.get_users(['krz7jwkviui2p3'])\n",
    "# post = course.get_post('3809')\n",
    "\n",
    "# p = course.get_feed()\n",
    "\n",
    "# text = json.dumps(post, sort_keys=True, indent=4)\n",
    "\n",
    "\n",
    "# users = course.get_all_users()\n",
    "\n",
    "# user\n",
    "\n",
    "# print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to handle posts with imgs? Do we want the img tags stripped? Think about how it will affect textual features\n",
    "response length, sentiment, \n",
    "\n",
    "what elements do q&a contain?\n",
    "latex, code snippets, imgs/screenshots, links, lists, annotations to prev posts (i.e. @356)\n",
    "\n",
    "fields that can be added: num_answer_imgs, ...\n",
    "\n",
    "can remove posts with imgs or include a special field called \"num_imgs\" so can distinguish b/w posts that have imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Feature Engineering - Transform csv into another csv with relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEPATH_CSV = \"./csc108_fall2021.csv\"\n",
    "AUGMENTED_FILEPATH_CSV = \"./csc108_fall2021_sentiment_aug.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_private</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question</th>\n",
       "      <th>folders</th>\n",
       "      <th>student_poster_name</th>\n",
       "      <th>date_question_posted</th>\n",
       "      <th>student_answer</th>\n",
       "      <th>student_answer_name</th>\n",
       "      <th>date_student_answer_posted</th>\n",
       "      <th>is_student_endorsed</th>\n",
       "      <th>is_student_helpful</th>\n",
       "      <th>instructor_answer</th>\n",
       "      <th>instructor_answer_name</th>\n",
       "      <th>date_instructor_answer_posted</th>\n",
       "      <th>is_instructor_helpful</th>\n",
       "      <th>is_followup</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>False</td>\n",
       "      <td>Spatial Skills: Pretest - Shapes difficult to ...</td>\n",
       "      <td>&lt;p&gt;Hello,&lt;/p&gt;\\n&lt;p&gt;&lt;/p&gt;\\n&lt;p&gt; As I was doing the...</td>\n",
       "      <td>spatial</td>\n",
       "      <td>ksoq5p0f71h12q</td>\n",
       "      <td>2021-08-24T04:42:07Z</td>\n",
       "      <td>&lt;p&gt;Its the dark mode making the shapes look od...</td>\n",
       "      <td>ksoq6px0rgz43d</td>\n",
       "      <td>2021-08-30T06:59:49Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;p&gt;Could you give us an example (screenshot) o...</td>\n",
       "      <td>gzcyozk0MBl</td>\n",
       "      <td>2021-08-24T04:45:41Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>False</td>\n",
       "      <td>Question I make based on Week 1 material</td>\n",
       "      <td>&lt;p&gt;Hello:&lt;/p&gt;\\n&lt;p&gt;There are question made by m...</td>\n",
       "      <td>general</td>\n",
       "      <td>keivl0bhdc52f5</td>\n",
       "      <td>2021-08-24T02:40:40Z</td>\n",
       "      <td>&lt;p&gt;Q1) 8**6//4&amp;#43;6&amp;#43;6*8&lt;/p&gt;\\n&lt;p&gt;   = 2621...</td>\n",
       "      <td>ksoq5rauj41c2</td>\n",
       "      <td>2021-08-25T06:55:53Z</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>Spatial skills: Orthographic Views 1, #3</td>\n",
       "      <td>&lt;p&gt;Hello:&lt;/p&gt;\\n&lt;p&gt;As I am doing the week 1 spa...</td>\n",
       "      <td>spatial</td>\n",
       "      <td>keivl0bhdc52f5</td>\n",
       "      <td>2021-08-23T20:08:34Z</td>\n",
       "      <td>&lt;p&gt;Just drop hints here: There will be some ed...</td>\n",
       "      <td>keivl0bhdc52f5</td>\n",
       "      <td>2021-08-23T21:17:37Z</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;p&gt;The key to this question is the dotted line...</td>\n",
       "      <td>k4ddfmb0gsb1h</td>\n",
       "      <td>2021-08-23T21:48:22Z</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>I don&amp;#39;t think I am in the right lecture</td>\n",
       "      <td>&lt;p&gt;I am currently enrolled in CSC108H5 F LEC 9...</td>\n",
       "      <td>lecture</td>\n",
       "      <td>ksoq61vj96i2d4</td>\n",
       "      <td>2021-08-23T19:23:56Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Hi Yaseen! Yes you are, all the lectures se...</td>\n",
       "      <td>k4ddfmb0gsb1h</td>\n",
       "      <td>2021-08-24T00:56:12Z</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>False</td>\n",
       "      <td>Ask Hints on Grading activities</td>\n",
       "      <td>&lt;p&gt;Hello:&lt;/p&gt;\\n&lt;p&gt;If when we are stuck on some...</td>\n",
       "      <td>general</td>\n",
       "      <td>keivl0bhdc52f5</td>\n",
       "      <td>2021-08-23T16:53:37Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;General questions -- ones that you can ask ...</td>\n",
       "      <td>gzcyozk0MBl</td>\n",
       "      <td>2021-08-23T17:01:32Z</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         is_private                                     question_title  \\\n",
       "post_id                                                                  \n",
       "16            False  Spatial Skills: Pretest - Shapes difficult to ...   \n",
       "15            False           Question I make based on Week 1 material   \n",
       "13             True           Spatial skills: Orthographic Views 1, #3   \n",
       "12            False        I don&#39;t think I am in the right lecture   \n",
       "10            False                    Ask Hints on Grading activities   \n",
       "\n",
       "                                                  question  folders  \\\n",
       "post_id                                                               \n",
       "16       <p>Hello,</p>\\n<p></p>\\n<p> As I was doing the...  spatial   \n",
       "15       <p>Hello:</p>\\n<p>There are question made by m...  general   \n",
       "13       <p>Hello:</p>\\n<p>As I am doing the week 1 spa...  spatial   \n",
       "12       <p>I am currently enrolled in CSC108H5 F LEC 9...  lecture   \n",
       "10       <p>Hello:</p>\\n<p>If when we are stuck on some...  general   \n",
       "\n",
       "        student_poster_name  date_question_posted  \\\n",
       "post_id                                             \n",
       "16           ksoq5p0f71h12q  2021-08-24T04:42:07Z   \n",
       "15           keivl0bhdc52f5  2021-08-24T02:40:40Z   \n",
       "13           keivl0bhdc52f5  2021-08-23T20:08:34Z   \n",
       "12           ksoq61vj96i2d4  2021-08-23T19:23:56Z   \n",
       "10           keivl0bhdc52f5  2021-08-23T16:53:37Z   \n",
       "\n",
       "                                            student_answer  \\\n",
       "post_id                                                      \n",
       "16       <p>Its the dark mode making the shapes look od...   \n",
       "15       <p>Q1) 8**6//4&#43;6&#43;6*8</p>\\n<p>   = 2621...   \n",
       "13       <p>Just drop hints here: There will be some ed...   \n",
       "12                                                     NaN   \n",
       "10                                                     NaN   \n",
       "\n",
       "        student_answer_name date_student_answer_posted is_student_endorsed  \\\n",
       "post_id                                                                      \n",
       "16           ksoq6px0rgz43d       2021-08-30T06:59:49Z               False   \n",
       "15            ksoq5rauj41c2       2021-08-25T06:55:53Z               False   \n",
       "13           keivl0bhdc52f5       2021-08-23T21:17:37Z                True   \n",
       "12                      NaN                        NaN                 NaN   \n",
       "10                      NaN                        NaN                 NaN   \n",
       "\n",
       "        is_student_helpful                                  instructor_answer  \\\n",
       "post_id                                                                         \n",
       "16                   False  <p>Could you give us an example (screenshot) o...   \n",
       "15                   False                                                NaN   \n",
       "13                   False  <p>The key to this question is the dotted line...   \n",
       "12                     NaN  <p>Hi Yaseen! Yes you are, all the lectures se...   \n",
       "10                     NaN  <p>General questions -- ones that you can ask ...   \n",
       "\n",
       "        instructor_answer_name date_instructor_answer_posted  \\\n",
       "post_id                                                        \n",
       "16                 gzcyozk0MBl          2021-08-24T04:45:41Z   \n",
       "15                         NaN                           NaN   \n",
       "13               k4ddfmb0gsb1h          2021-08-23T21:48:22Z   \n",
       "12               k4ddfmb0gsb1h          2021-08-24T00:56:12Z   \n",
       "10                 gzcyozk0MBl          2021-08-23T17:01:32Z   \n",
       "\n",
       "        is_instructor_helpful  is_followup  \n",
       "post_id                                     \n",
       "16                      False         True  \n",
       "15                        NaN         True  \n",
       "13                      False         True  \n",
       "12                       True        False  \n",
       "10                       True         True  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(FILEPATH_CSV, index_col=0)\n",
    "data.tail()\n",
    "\n",
    "# data.keys()\n",
    "# students = data[data[' is_student_endorsed'] == True]['student_answer_name']\n",
    "# for s in students:\n",
    "#     print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New schema: (post_id,student_poster_id,close_to_deadline, \"is_followup\"\" \n",
    "    \n",
    "    \"answerer_id, date_answer_posted, reputation, is_helpful\"\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "    date_question_posted\n",
    "    - close to deadline: yes/no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/Brandon/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length(text:str) -> int:\n",
    "    length = 0\n",
    "    if isinstance(text, str):\n",
    "        length = len(word_tokenize(text))\n",
    "    else: # must be nan\n",
    "        if not isnan(text):\n",
    "            assert(1 == 0) # shouldn't get here\n",
    "    \n",
    "    return length\n",
    "\n",
    "\n",
    "def is_references(text: str) -> bool:\n",
    "    \"\"\" Check if answer contains a link to another post (i.e. @256) or a hyperlink\n",
    "        :param text: question|answer with html stripping \n",
    "    \"\"\"   \n",
    "    return True if re.search(r'@+\\d', text) or 'http' in text else False\n",
    "\n",
    "def level_of_detail(text: str) -> bool:\n",
    "    \"\"\" Detect imgs or code snippets\n",
    "        :param text: raw question|answer without html stripping so can detect imgs/code-snippets\n",
    "    \"\"\"\n",
    "    is_image = True if '<img' in text else False\n",
    "    is_code_snippets = True if '<pre' in text else False\n",
    "\n",
    "    return True if is_image or is_code_snippets else False\n",
    "\n",
    "\n",
    "def answer_response_time(t1:str, t2:str) -> int:\n",
    "    \"\"\":returns: Answer response time in mins, rounded up. Add option to use log scale?\"\"\"\n",
    "    d1 = datetime.fromisoformat(t1[:-1])\n",
    "    d2 = datetime.fromisoformat(t2[:-1])\n",
    "    delta = d2-d1\n",
    "    response_time = math.ceil(delta.total_seconds() // 60)\n",
    "    if response_time == 0:\n",
    "        response_time = EPSILON\n",
    "    return response_time\n",
    "    \n",
    "def get_category(folder: str, folder_set: dict[str, int]) -> int:\n",
    "    \"\"\" For multi-categories just choose the 1st one.\n",
    "        Varies b/w classes.\n",
    "\n",
    "        :param folder: folder1,folder2, ...\n",
    "        :param folder_set: set of all folders\n",
    "\n",
    "        Precondition: folder should be part of folder_set\n",
    "\n",
    "    \"\"\"\n",
    "    category = folder.split(',')[0]\n",
    "    if category not in folder_set:\n",
    "        assert(1 == 0)\n",
    "\n",
    "    return folder_set[category]\n",
    "\n",
    "\n",
    "def get_sentiment(text: str, sentiment_model) -> int:\n",
    "    \n",
    "    senti = sentiment_model(text)[0]['label']\n",
    "    if senti == 'LABEL_0':\n",
    "        return LABEL_0\n",
    "    elif senti == 'LABEL_1':\n",
    "        return LABEL_1\n",
    "    else:\n",
    "        return LABEL_2\n",
    "\n",
    "    \n",
    "\n",
    "def add_answer(augmented_data:List[List], append_row:List, post_row:tuple, poster_dict: Dict[str, str], num_instances:int, answer_type:int) -> int:\n",
    "    \"\"\"\n",
    "    Append student or instructor answer fields to augmented_data.\n",
    "\n",
    "    :param augmented_data: table to add append_row to\n",
    "    :param append_row: partially filled row to be completed\n",
    "    :param post_row: namedtuple containing information about the current Piazza post\n",
    "    :param answer_type: INSTRUCTOR|STUDENT\n",
    "    :returns: this is a description of what is returned\n",
    "    :raises Nothing\n",
    "    \"\"\"\n",
    "    poster =  'student' if answer_type == STUDENT  else 'instructor'\n",
    "    fields = [f'{poster}_answer', f'{poster}_answer_name', f'is_{poster}_helpful', 'date_{poster}_answer_posted']\n",
    "    increment_num_instances = False\n",
    "    \n",
    "    answer = getattr(post_row, f\"{poster}_answer\")\n",
    "   \n",
    "    if isinstance(answer, str): \n",
    "        stripped_answer = strip_tags(answer)\n",
    "        poster_id = getattr(post_row, f'{poster}_answer_name')\n",
    "        if poster_id not in poster_dict:\n",
    "            poster_dict[poster_id] = num_instances \n",
    "            increment_num_instances = True\n",
    "\n",
    "        is_helpful = 1 if getattr(post_row, f\"is_{poster}_helpful\") else 0\n",
    "\n",
    "        \n",
    "\n",
    "        append_row.append(poster_dict[poster_id])\n",
    "        append_row.append(get_length(stripped_answer))\n",
    "        append_row.append(is_references(stripped_answer))\n",
    "        append_row.append(level_of_detail(answer))\n",
    "\n",
    "        t1 = getattr(post_row, 'date_question_posted')\n",
    "        t2 = getattr(post_row, f'date_{poster}_answer_posted')\n",
    "        response_time = answer_response_time(t1, t2)\n",
    "\n",
    "\n",
    "        append_row.append(response_time)\n",
    "        \n",
    "        append_row.append(answer_type)\n",
    "        append_row.append(is_helpful)\n",
    "        augmented_data.append(append_row)\n",
    "\n",
    "    return increment_num_instances\n",
    "\n",
    "    \n",
    "#'general,lecture'.split(',')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████| 1.08k/1.08k [00:00<00:00, 351kB/s]\n"
     ]
    }
   ],
   "source": [
    "sentiment_pipeline = pipeline(model=\"cardiffnlp/twitter-roberta-base-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "439it [02:09,  3.38it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1231) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 1231].  Tensor sizes: [1, 514]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 59>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m augmented_df\n\u001b[1;32m     57\u001b[0m csc108_fall2021_categories \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneral\u001b[39m\u001b[38;5;124m'\u001b[39m: GENERAL, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlecture\u001b[39m\u001b[38;5;124m'\u001b[39m: LECTURES, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlab\u001b[39m\u001b[38;5;124m'\u001b[39m: ASSIGNMENTS , \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtests/exam\u001b[39m\u001b[38;5;124m'\u001b[39m: TESTS, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutm/life/other\u001b[39m\u001b[38;5;124m'\u001b[39m: GENERAL, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspatial\u001b[39m\u001b[38;5;124m'\u001b[39m: ASSIGNMENTS, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpcrs\u001b[39m\u001b[38;5;124m'\u001b[39m: ASSIGNMENTS}\n\u001b[0;32m---> 59\u001b[0m augmented_df \u001b[38;5;241m=\u001b[39m \u001b[43maugment_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsc108_fall2021_categories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentiment_pipeline\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#augmented_data[0].shape\u001b[39;00m\n\u001b[1;32m     62\u001b[0m augmented_df\u001b[38;5;241m.\u001b[39mto_csv(AUGMENTED_FILEPATH_CSV)\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36maugment_data\u001b[0;34m(data, folder_set, sentiment_model)\u001b[0m\n\u001b[1;32m     29\u001b[0m     stripped_q \u001b[38;5;241m=\u001b[39m strip_tags(r\u001b[38;5;241m.\u001b[39mquestion)\n\u001b[1;32m     30\u001b[0m     raw_question \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mquestion\n\u001b[0;32m---> 31\u001b[0m     question_sentiment \u001b[38;5;241m=\u001b[39m \u001b[43mget_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstripped_q\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentiment_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m new_row\u001b[38;5;241m.\u001b[39mappend(get_length(stripped_q))\n\u001b[1;32m     35\u001b[0m new_row\u001b[38;5;241m.\u001b[39mappend(is_references(stripped_q))\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mget_sentiment\u001b[0;34m(text, sentiment_model)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sentiment\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m, sentiment_model) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m---> 57\u001b[0m     senti \u001b[38;5;241m=\u001b[39m \u001b[43msentiment_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m senti \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLABEL_0\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m LABEL_0\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:125\u001b[0m, in \u001b[0;36mTextClassificationPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    Classify the text(s) given as inputs.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m        If `self.return_all_scores=True`, one such dictionary is returned per label.\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    127\u001b[0m         \u001b[38;5;66;03m# This pipeline is odd, and return a list when single item is run\u001b[39;00m\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [result]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/pipelines/base.py:1026\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterate(inputs, preprocess_params, forward_params, postprocess_params)\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/pipelines/base.py:1033\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1032\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1033\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1034\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/pipelines/base.py:943\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m    942\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 943\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    944\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:137\u001b[0m, in \u001b[0;36mTextClassificationPipeline._forward\u001b[0;34m(self, model_inputs)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_inputs):\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:1209\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1207\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1209\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1220\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1221\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:817\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    816\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[0;32m--> 817\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    818\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1231) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 1231].  Tensor sizes: [1, 514]"
     ]
    }
   ],
   "source": [
    "from math import isnan\n",
    "\n",
    "def augment_data(data: DataFrame, folder_set: dict[str, int], sentiment_model) -> DataFrame:\n",
    "\n",
    "    augmented_data = []\n",
    "\n",
    "    studentid_to_int = {}\n",
    "    instructorid_to_int = {}\n",
    "    num_students, num_instructors = 0, 0\n",
    "\n",
    "    #sentiment_pipeline = pipeline(model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "    for r in tqdm(data.itertuples()):\n",
    "       \n",
    "        new_row = [r.Index] \n",
    "        new_row.append(r.is_private)\n",
    "        category = get_category(r.folders, folder_set)\n",
    "        new_row.append(category)\n",
    "       \n",
    "        if r.student_poster_name not in studentid_to_int:\n",
    "            studentid_to_int[r.student_poster_name] = num_students \n",
    "            num_students += 1\n",
    "            \n",
    "        new_row.append(studentid_to_int[r.student_poster_name])\n",
    "        stripped_q = \"\"\n",
    "        raw_question = \"\"\n",
    "        question_sentiment = \"\"\n",
    "        if isinstance(r.question, str): \n",
    "            stripped_q = strip_tags(r.question)\n",
    "            raw_question = r.question\n",
    "            question_sentiment = get_sentiment(stripped_q, sentiment_model)\n",
    "\n",
    "       \n",
    "        new_row.append(get_length(stripped_q))\n",
    "        new_row.append(is_references(stripped_q))\n",
    "        new_row.append(level_of_detail(raw_question))\n",
    "        new_row.append(question_sentiment)\n",
    "\n",
    "\n",
    "    \n",
    "        is_followup = 1 if r.is_followup else 0\n",
    "        new_row.append(is_followup)\n",
    "\n",
    "        # add separate rows for student and instructor answer\n",
    "        num_students += add_answer(augmented_data, deepcopy(new_row), r, studentid_to_int, num_students, STUDENT)\n",
    "        num_instructors += add_answer(augmented_data, deepcopy(new_row), r, instructorid_to_int, num_instructors, INSTRUCTOR)\n",
    "\n",
    "    \n",
    "    augmented_data = np.array(augmented_data)\n",
    "    augmented_df = pd.DataFrame(augmented_data, columns=['post_id', 'is_private', 'category', 'student_poster_id', \n",
    "    'question_length', 'is_question_references', 'question_lod', 'question_sentiment', 'is_followup', \n",
    "    'answerer_id', 'answer_length', 'is_answer_references', 'answer_lod', 'response_time',  'reputation', 'is_helpful'])\n",
    "\n",
    "    return augmented_df\n",
    "\n",
    "\n",
    "csc108_fall2021_categories = {'general': GENERAL, 'lecture': LECTURES, 'lab': ASSIGNMENTS , 'tests/exam': TESTS, 'utm/life/other': GENERAL, 'spatial': ASSIGNMENTS, 'pcrs': ASSIGNMENTS}\n",
    "\n",
    "augmented_df = augment_data(data, csc108_fall2021_categories, sentiment_pipeline)\n",
    "#augmented_data[0].shape\n",
    "\n",
    "augmented_df.to_csv(AUGMENTED_FILEPATH_CSV)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>is_private</th>\n",
       "      <th>category</th>\n",
       "      <th>student_poster_id</th>\n",
       "      <th>question_length</th>\n",
       "      <th>is_question_references</th>\n",
       "      <th>question_lod</th>\n",
       "      <th>is_followup</th>\n",
       "      <th>answerer_id</th>\n",
       "      <th>answer_length</th>\n",
       "      <th>is_answer_references</th>\n",
       "      <th>answer_lod</th>\n",
       "      <th>response_time</th>\n",
       "      <th>reputation</th>\n",
       "      <th>is_helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3809.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3808.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3807.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3807.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3806.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  is_private  category  student_poster_id  question_length  \\\n",
       "0   3809.0         1.0       0.0                0.0             23.0   \n",
       "1   3808.0         0.0       0.0                1.0             53.0   \n",
       "2   3807.0         0.0       2.0                3.0              0.0   \n",
       "3   3807.0         0.0       2.0                3.0              0.0   \n",
       "4   3806.0         1.0       0.0                5.0             93.0   \n",
       "\n",
       "   is_question_references  question_lod  is_followup  answerer_id  \\\n",
       "0                     0.0           0.0          0.0          0.0   \n",
       "1                     0.0           0.0          0.0          2.0   \n",
       "2                     0.0           0.0          0.0          4.0   \n",
       "3                     0.0           0.0          0.0          0.0   \n",
       "4                     0.0           0.0          1.0          1.0   \n",
       "\n",
       "   answer_length  is_answer_references  answer_lod  response_time  reputation  \\\n",
       "0           27.0                   0.0         0.0           43.0         1.0   \n",
       "1           48.0                   0.0         0.0            6.0         0.0   \n",
       "2            3.0                   1.0         0.0            2.0         0.0   \n",
       "3           43.0                   1.0         0.0            3.0         1.0   \n",
       "4           32.0                   0.0         0.0            1.0         1.0   \n",
       "\n",
       "   is_helpful  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         0.0  \n",
       "3         0.0  \n",
       "4         0.0  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_df.head()\n",
    "#augmented_df[augmented_df['response_time'] < 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.08k/1.08k [00:00<00:00, 1.02MB/s]\n",
      "Downloading: 100%|██████████| 747/747 [00:00<00:00, 745kB/s]\n",
      "Downloading: 100%|██████████| 476M/476M [00:07<00:00, 67.4MB/s] \n",
      "Downloading: 100%|██████████| 878k/878k [00:00<00:00, 1.60MB/s]\n",
      "Downloading: 100%|██████████| 446k/446k [00:00<00:00, 2.69MB/s]\n",
      "Downloading: 100%|██████████| 150/150 [00:00<00:00, 146kB/s]\n"
     ]
    }
   ],
   "source": [
    "# a = 0\n",
    "# a += False\n",
    "# a\n",
    "# sentence = \"How the Meta skill be graded, I only got 22 of the marks, however I have finished all the meta skills with answering all the questions,how that happened, thank you so much!\"\n",
    "# s2 = \"num_col = longest_chain(matrix[row][col:]) num_rows = 1  temp_last_col = 0 largest_matrix = num_col * num_rows\"\n",
    "# tokenized = word_tokenize(s2)\n",
    "# print(tokenized)\n",
    "\n",
    "# print(get_length('https://youtube.com/channel/UCu8NnRGTGxHe96Le0xqLrNQ'))\n",
    "# word_tokenize('https://youtube.com/channel/UCu8NnRGTGxHe96Le0xqLrNQ')\n",
    "\n",
    "# match = re.search(r'@+\\d', 'check@blah')\n",
    "# #print(match)\n",
    "\n",
    "# sentiment_pipeline = pipeline(model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "0  8  9\n",
       "1  8  9\n",
       "2  8  9"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = [\"Thank you so much for your hard work over the semester, professors and TAs!! \"]\n",
    "# sentiment_pipeline(data)\n",
    "\n",
    "# df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
    "# df['A'] = df['A'].apply(lambda x: x * 2)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] https://stackoverflow.com/questions/753052/strip-html-from-strings-in-python"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
